ğŸ” **Verification & Validation â€” Comprehensive Cheatsheet**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**Context:** DO-178C compliance for airborne software systems  
**Focus:** Requirements-based testing, structural coverage, integration strategies  
**Target Audience:** V&V engineers, test managers, certification authorities

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

.. contents:: ğŸ“‘ Quick Navigation
   :depth: 2
   :local:

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ **TL;DR â€” V&V IN 60 SECONDS**
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

**The Two Questions:**

âœ… **Verification:** "Are we building the product **right**?"  
   â†’ Does code implement requirements correctly?

âœ… **Validation:** "Are we building the **right** product?"  
   â†’ Do requirements meet stakeholder needs?

**Memorization Device: "Right vs. Right Product"**

.. code-block:: text

   Requirements â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Design â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Code
        â”‚                      â”‚                  â”‚
        â”‚ Validation           â”‚ Verification     â”‚ Verification
        â–¼                      â–¼                  â–¼
   "Right product?"      "Correct design?"   "Bug-free code?"

**Key Coverage Metrics (DAL A):**

+-----------------+----------+-----------+-----------+
| Coverage Type   | DAL A    | DAL B     | DAL C     |
+=================+==========+===========+===========+
| **MC/DC**       | âœ… 100%  | âœ… 100%   | âŒ N/A    |
| **Decision**    | âœ… 100%  | âœ… 100%   | âœ… 100%   |
| **Statement**   | âœ… 100%  | âœ… 100%   | âœ… 100%   |
+-----------------+----------+-----------+-----------+

**The V-Model (Simplified):**

.. code-block:: text

   Requirements â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º System Test
        â–¼                                      â–²
   High-Level Design â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Integration Test
        â–¼                                      â–²
   Low-Level Design â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Module Test
        â–¼                                      â–²
        â””â”€â”€â”€â”€â”€â”€â”€â”€â–º Source Code â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   (Unit Test)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“– **1. VERIFICATION VS. VALIDATION â€” THE FUNDAMENTALS**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**IEEE Definitions:**

ğŸ” **Verification (IEEE 1012)**  
   "The process of evaluating a system or component to determine whether 
   the products of a given development phase satisfy the conditions 
   imposed at the start of that phase."

   **Translation:** Did we follow the blueprint correctly?

âœ… **Validation (IEEE 1012)**  
   "The process of evaluating a system or component during or at the end 
   of the development process to determine whether it satisfies specified 
   requirements."

   **Translation:** Is this what the customer actually needs?

**Practical Examples:**

+--------------------------------+--------------------------------+
| Verification (Building Right)  | Validation (Right Product)     |
+================================+================================+
| Code review against low-level  | User acceptance test (UAT)     |
| requirements                   |                                |
+--------------------------------+--------------------------------+
| Traceability analysis          | Pilot-in-the-loop simulation   |
| (Req â†’ Code â†’ Test)            | (operational scenario)         |
+--------------------------------+--------------------------------+
| MC/DC coverage analysis        | Stakeholder review of HLR      |
| (100% for DAL A)               | (before design starts)         |
+--------------------------------+--------------------------------+
| Static code analysis           | Flight test campaign           |
| (MISRA C, Polyspace)           | (actual aircraft operation)    |
+--------------------------------+--------------------------------+

**Mnemonic: "VVVC" (Verify Validate Verify Code)**
- **V**alidate requirements (right product)
- **V**erify design (correct architecture)
- **V**erify code (implements design)
- **C**ertify system (regulatory acceptance)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ§ª **2. REQUIREMENTS-BASED TESTING**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**DO-178C Objective:** Every requirement must have at least one test case

**Test Case Structure (DO-178C Compliant):**

.. code-block:: text

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Test Case ID: TC-FCC-001                                â”‚
   â”‚ Requirement: REQ-FCC-123 "Autopilot engages at >500 ft" â”‚
   â”‚                                                          â”‚
   â”‚ Preconditions:                                          â”‚
   â”‚   â€¢ Aircraft on ground (altitude = 0 ft)                â”‚
   â”‚   â€¢ Engines running                                     â”‚
   â”‚   â€¢ Autopilot armed but not engaged                     â”‚
   â”‚                                                          â”‚
   â”‚ Test Steps:                                             â”‚
   â”‚   1. Takeoff and climb to 499 ft MSL                    â”‚
   â”‚   2. Press "AP ENGAGE" button                           â”‚
   â”‚   3. Verify autopilot does NOT engage (Expected)        â”‚
   â”‚   4. Continue climb to 500 ft MSL                       â”‚
   â”‚   5. Press "AP ENGAGE" button again                     â”‚
   â”‚   6. Verify autopilot ENGAGES (Expected)                â”‚
   â”‚                                                          â”‚
   â”‚ Expected Results:                                       â”‚
   â”‚   â€¢ Step 3: AP_STATUS = "ARMED" (not "ENGAGED")         â”‚
   â”‚   â€¢ Step 6: AP_STATUS = "ENGAGED"                       â”‚
   â”‚                                                          â”‚
   â”‚ Pass/Fail Criteria:                                     â”‚
   â”‚   PASS if both expected results match actual            â”‚
   â”‚   FAIL if autopilot engages below 500 ft                â”‚
   â”‚                                                          â”‚
   â”‚ Traceability:                                           â”‚
   â”‚   REQ-FCC-123 â†’ LLR-FCC-456 â†’ TC-FCC-001               â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

**Coverage Matrix Example:**

+-------------+------------------+------------------+-----------+
| Requirement | Test Case        | Verification     | Status    |
|             |                  | Method           |           |
+=============+==================+==================+===========+
| REQ-FCC-123 | TC-FCC-001       | Test (T)         | âœ… Passed |
|             | TC-FCC-002       | Analysis (A)     | âœ… Passed |
+-------------+------------------+------------------+-----------+
| REQ-FCC-124 | TC-FCC-003       | Test (T)         | âš ï¸ Review |
+-------------+------------------+------------------+-----------+
| REQ-FCC-125 | TC-FCC-004       | Inspection (I)   | âœ… Passed |
|             | TC-FCC-005       | Test (T)         | âœ… Passed |
+-------------+------------------+------------------+-----------+

**Verification Methods (DO-178C Table A-3):**

ğŸ“ **T (Test):**  
   Execute code with inputs, observe outputs

ğŸ” **I (Inspection):**  
   Manual review (e.g., code walk-through)

ğŸ“Š **A (Analysis):**  
   Mathematical proof, simulation, timing analysis

ğŸ¯ **D (Demonstration):**  
   Qualitative check (e.g., GUI layout)

**Normal-Case vs. Robustness Testing:**

.. code-block:: text

   Normal Case:     Valid inputs â†’ Expected outputs
   Example:         altitude = 500 ft â†’ AP engages

   Robustness:      Invalid/edge inputs â†’ Safe handling
   Example:         altitude = -999 ft â†’ AP does NOT engage
                    altitude = NULL â†’ Error logged, AP disabled

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š **3. STRUCTURAL COVERAGE ANALYSIS**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**Coverage Hierarchy (Strictest to Weakest):**

.. code-block:: text

   MC/DC (Modified Condition/Decision Coverage)
     â”‚
     â”œâ”€â–º Decision Coverage
     â”‚      â”‚
     â”‚      â””â”€â–º Branch Coverage
     â”‚             â”‚
     â”‚             â””â”€â–º Statement Coverage
     â”‚                    â”‚
     â”‚                    â””â”€â–º Function Coverage

**3.1 Statement Coverage**

**Definition:** Every executable statement runs at least once

**Example Code:**

.. code-block:: c

   void autopilot_engage(int altitude, bool button_pressed) {
       if (altitude > 500) {          // Line 1
           if (button_pressed) {      // Line 2
               engage_autopilot();    // Line 3
           }
       }
       log_status();                  // Line 4
   }

**Test Cases for 100% Statement Coverage:**

+----------+----------+------------------+-------------------+
| Test     | altitude | button_pressed   | Lines Executed    |
+==========+==========+==================+===================+
| TC1      | 600      | true             | 1, 2, 3, 4        |
| TC2      | 400      | false            | 1, 4              |
+----------+----------+------------------+-------------------+

**Result:** All 4 lines executed â†’ âœ… 100% Statement Coverage

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

**3.2 Decision Coverage (Branch Coverage)**

**Definition:** Each boolean expression evaluates to both TRUE and FALSE

**Test Cases for 100% Decision Coverage:**

+----------+----------+------------------+-------------------+
| Test     | altitude | button_pressed   | Decisions         |
+==========+==========+==================+===================+
| TC1      | 600      | true             | (L1=T, L2=T)      |
| TC2      | 400      | false            | (L1=F)            |
| TC3      | 600      | false            | (L2=F)            |
+----------+----------+------------------+-------------------+

**Result:**  
- Line 1: T (TC1) and F (TC2) â†’ âœ…  
- Line 2: T (TC1) and F (TC3) â†’ âœ…  
â†’ **100% Decision Coverage**

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

**3.3 MC/DC (Modified Condition/Decision Coverage)**

**Definition:** Each condition in a decision independently affects the outcome

**Complex Example:**

.. code-block:: c

   // Autopilot engages if:
   // altitude > 500 AND button_pressed AND NOT hydraulic_fail
   
   if (altitude > 500 && button_pressed && !hydraulic_fail) {
       engage_autopilot();
   }

**Conditions:**
- A: altitude > 500
- B: button_pressed
- C: !hydraulic_fail

**Decision:** D = A AND B AND C

**MC/DC Test Matrix:**

+----+---+---+---+---+------------------------+
| TC | A | B | C | D | Independence Check     |
+====+===+===+===+===+========================+
| 1  | T | T | T | T | (baseline TRUE)        |
+----+---+---+---+---+------------------------+
| 2  | F | T | T | F | A alone changed D      |
|    |   |   |   |   | (proves A's influence) |
+----+---+---+---+---+------------------------+
| 3  | T | F | T | F | B alone changed D      |
+----+---+---+---+---+------------------------+
| 4  | T | T | F | F | C alone changed D      |
+----+---+---+---+---+------------------------+

**Minimum MC/DC Tests: N+1 (where N = # of conditions)**  
For 3 conditions â†’ 4 test cases minimum

**MC/DC Visualization:**

.. code-block:: text

   Condition A flips:
   TC1: (T,T,T) â†’ D=T  }
   TC2: (F,T,T) â†’ D=F  }â”€â–º A independently affects D âœ…

   Condition B flips:
   TC1: (T,T,T) â†’ D=T  }
   TC3: (T,F,T) â†’ D=F  }â”€â–º B independently affects D âœ…

   Condition C flips:
   TC1: (T,T,T) â†’ D=T  }
   TC4: (T,T,F) â†’ D=F  }â”€â–º C independently affects D âœ…

**Why MC/DC for DAL A?**

ğŸ’€ **Without MC/DC:** Bug could hide in untested condition combinations  
âœ… **With MC/DC:** Every condition proven to matter independently

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ§° **4. COVERAGE TOOLS & AUTOMATION**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**Tool Qualification (DO-178C Â§12.2):**

.. code-block:: text

   Coverage Tool (e.g., VectorCAST, LDRA)
       â”‚
       â”œâ”€â–º Tool Qualification Level (TQL)
       â”‚   â””â”€â–º TQL-1: Tool output used as DO-178C evidence
       â”‚       (requires Tool Qualification Data Package)
       â”‚
       â””â”€â–º Verification Methods
           â”œâ”€â–º Tool Operational Requirements (TOR)
           â”œâ”€â–º Test cases for tool itself
           â””â”€â–º Service history / conformity review

**Popular Coverage Tools:**

ğŸ› ï¸ **VectorCAST (Vector Software)**  
   - MC/DC, statement, branch coverage
   - Automated test harness generation
   - DO-178C qualified (TQL-1 compliant)

ğŸ› ï¸ **LDRA Testbed**  
   - Static + dynamic analysis
   - MISRA C/C++ checking
   - Coverage visualization

ğŸ› ï¸ **Rapita Verification Suite (RVS)**  
   - Timing analysis + coverage
   - Target hardware support (PowerPC, ARM)

ğŸ› ï¸ **CTC++ (Testwell)**  
   - Embedded C/C++ coverage
   - Host-target cross-compilation

**Tool Workflow Example:**

.. code-block:: bash

   # Step 1: Instrument source code
   vectorcast instrument autopilot.c -o autopilot_inst.c
   
   # Step 2: Compile instrumented code
   gcc autopilot_inst.c -o autopilot_test
   
   # Step 3: Run test cases
   ./autopilot_test < test_inputs.txt
   
   # Step 4: Generate coverage report
   vectorcast report --format html --mcdc
   
   # Output: coverage_report.html
   # Shows: 100% MC/DC (24/24 conditions tested)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”¬ **5. INTEGRATION TESTING STRATEGIES**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**Integration Levels (Bottom-Up):**

.. code-block:: text

   Level 1: Module/Unit Test
       â”œâ”€â–º Individual functions tested in isolation
       â””â”€â–º Stubs for dependencies
   
   Level 2: Component Integration
       â”œâ”€â–º Multiple modules combined
       â””â”€â–º Test interfaces between components
   
   Level 3: Subsystem Integration
       â”œâ”€â–º Major subsystems (e.g., FCC + sensors)
       â””â”€â–º Hardware-in-the-loop (HIL) testing
   
   Level 4: System Integration
       â”œâ”€â–º Complete aircraft system
       â””â”€â–º Iron-bird rig or flight test

**Integration Approaches:**

**A. Big Bang Integration âŒ (Not recommended for safety-critical)**

.. code-block:: text

   All modules â†’ Integrate at once â†’ Hope it works
   Problem: Too many variables, hard to isolate bugs

**B. Incremental Integration âœ… (DO-178C preferred)**

.. code-block:: text

   Module A â”€â”€â”
              â”œâ”€â–º Test A+B â”€â”€â”
   Module B â”€â”€â”˜              â”œâ”€â–º Test A+B+C â”€â”€â–º ...
                             â”‚
   Module C â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

**C. Sandwich Integration (Hybrid)**

.. code-block:: text

   Top-Down:    GUI â†’ Controller â†’ (stubs)
   Bottom-Up:   (drivers) â†’ Sensors â†’ Actuators
   Middle:      Join the two layers at integration test

**Example: Flight Control Computer Integration**

.. code-block:: text

   Step 1: Unit Test
       â”œâ”€â–º pitch_controller() tested with stubs
       â”œâ”€â–º roll_controller() tested with stubs
       â””â”€â–º yaw_controller() tested with stubs
   
   Step 2: Component Integration
       â”œâ”€â–º Combine pitch + roll + yaw controllers
       â”œâ”€â–º Test with simulated sensor inputs
       â””â”€â–º Verify control law coordination
   
   Step 3: Subsystem Integration (HIL)
       â”œâ”€â–º Real sensors (IMU, GPS, air data)
       â”œâ”€â–º Real actuators (servo motors)
       â””â”€â–º Test in iron-bird rig (6DOF motion platform)
   
   Step 4: System Integration (Flight Test)
       â”œâ”€â–º Install in actual aircraft
       â”œâ”€â–º Test envelope expansion (low speed â†’ high speed)
       â””â”€â–º Certification authority witnessed flights

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ **6. TRACEABILITY â€” THE GOLDEN THREAD**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**Bi-Directional Traceability (DO-178C Â§6.3):**

.. code-block:: text

   Stakeholder Needs
         â†•
   System Requirements (HLR)
         â†•
   Software High-Level Requirements (HLR)
         â†•
   Software Low-Level Requirements (LLR)
         â†•
   Source Code
         â†•
   Test Cases
         â†•
   Test Results

**Forward Traceability:**  
HLR â†’ LLR â†’ Code â†’ Test Cases  
*Proves: "Every requirement is implemented and tested"*

**Backward Traceability:**  
Test Cases â†’ Code â†’ LLR â†’ HLR  
*Proves: "No orphan code (untraceable to requirements)"*

**Example Traceability Matrix:**

+---------+---------+--------------+--------------+-----------+
| HLR     | LLR     | Source File  | Test Case    | Status    |
+=========+=========+==============+==============+===========+
| HLR-001 | LLR-023 | autopilot.c  | TC-AP-001    | âœ… Passed |
|         | LLR-024 | autopilot.c  | TC-AP-002    | âœ… Passed |
+---------+---------+--------------+--------------+-----------+
| HLR-002 | LLR-025 | navigation.c | TC-NAV-001   | âš ï¸ Failed |
+---------+---------+--------------+--------------+-----------+

**Orphan Detection:**

.. code-block:: sql

   -- Find code not traced to requirements
   SELECT source_file, function_name 
   FROM source_code 
   WHERE function_name NOT IN (SELECT code_ref FROM traceability);
   
   -- Result: Warning! Potential dead code or undocumented feature

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš ï¸ **7. COMMON V&V PITFALLS**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âŒ **Pitfall 1: "We have 100% code coverage, we're done!"**

**Problem:** Code coverage â‰  requirements coverage

**Example:**  
âœ… Every line executed  
âŒ But missing test for "autopilot should NOT engage below 500 ft"

**Solution:** Requirements-based testing FIRST, then verify coverage

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âŒ **Pitfall 2: Writing tests after code is frozen**

**Problem:** Tests become "verification theater" (just to pass)

**Solution:** Test-Driven Development (TDD) for DO-178C:
1. Write requirement
2. Write test case (expected to fail initially)
3. Write code to pass the test
4. Refactor code, test remains stable

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âŒ **Pitfall 3: Ignoring equivalence partitioning**

**Problem:** Testing 500, 501, 502 ft individually (redundant)

**Solution:** Partition input space:

.. code-block:: text

   Partition 1: altitude < 500 (invalid)
   Partition 2: altitude = 500 (boundary)
   Partition 3: altitude > 500 (valid)
   
   Test: One case per partition + boundaries

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âŒ **Pitfall 4: Not testing failure modes**

**Problem:** Only testing happy path (normal operation)

**Solution:** Robustness testing:
- Sensor failure (GPS unavailable)
- Communication timeout (CAN bus down)
- Out-of-range values (altitude = -99999)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âŒ **Pitfall 5: Using modified code for coverage**

**Problem:** Developer tweaks code to hit 100% coverage

**Solution:** Configuration management:
- Coverage measured on BASELINED code
- No changes allowed without CCB approval
- Version control (Git tags for DO-178C releases)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ› ï¸ **8. PRACTICAL V&V WORKFLOW (DAL C Example)**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**Project:** Cabin Pressure Controller (DAL C)

**Phase 1: Requirements Analysis**

.. code-block:: text

   1. Receive System Requirements from aircraft OEM
   2. Derive Software High-Level Requirements (HLR)
      Example: "System shall maintain 8,000 ft cabin alt at 41,000 ft cruise"
   3. Validation: Stakeholder review (engineers + pilots)
   4. Traceability: Map HLR to System Req

**Phase 2: Design & Low-Level Requirements**

.. code-block:: text

   1. Create software architecture (control loop diagram)
   2. Derive Low-Level Requirements (LLR)
      Example: "PID controller shall run at 10 Hz"
   3. Verification: Design review, analysis
   4. Traceability: Map LLR to HLR

**Phase 3: Coding**

.. code-block:: text

   1. Implement LLR in C (MISRA C:2012 compliant)
   2. Peer code review (at least 2 reviewers)
   3. Static analysis (Polyspace, Coverity)
   4. Traceability: Map code to LLR

**Phase 4: Unit Testing**

.. code-block:: text

   1. Write test cases for each LLR
   2. Run tests with instrumented code (VectorCAST)
   3. Measure coverage:
      âœ… Statement: 100%
      âœ… Decision: 100%
      âŒ MC/DC: Not required for DAL C
   4. Traceability: Map tests to LLR

**Phase 5: Integration Testing**

.. code-block:: text

   1. Integrate with pressure sensors + outflow valves
   2. Hardware-in-the-loop (HIL) rig testing
   3. Test scenarios:
      - Normal climb to cruise
      - Emergency descent
      - Dual sensor failure
   4. Traceability: Map tests to HLR

**Phase 6: Certification**

.. code-block:: text

   1. Generate DO-178C deliverables:
      - Software Accomplishment Summary (SAS)
      - Software Configuration Index (SCI)
      - Problem reports log
      - Traceability matrices
   2. DER (Designated Engineering Representative) review
   3. FAA/EASA approval

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‡ **9. QUICK REFERENCE CARD**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**Coverage Requirements by DAL:**

+------------+-----------+----------+----------+----------+
| DAL Level  | Statement | Decision | MC/DC    | Priority |
+============+===========+==========+==========+==========+
| **A**      | âœ… 100%   | âœ… 100%  | âœ… 100%  | Highest  |
| **B**      | âœ… 100%   | âœ… 100%  | âœ… 100%  | High     |
| **C**      | âœ… 100%   | âœ… 100%  | âŒ N/A   | Medium   |
| **D**      | âœ… 100%   | âš ï¸ Goal  | âŒ N/A   | Low      |
| **E**      | âš ï¸ Goal   | âŒ N/A   | âŒ N/A   | Minimal  |
+------------+-----------+----------+----------+----------+

**Verification Methods (DO-178C):**

- **T (Test):** Execute code, observe results
- **I (Inspection):** Manual review (peer, walkthrough)
- **A (Analysis):** Mathematical proof, timing calculation
- **D (Demonstration):** Qualitative check (GUI, cosmetic)

**MC/DC Formula:**

Minimum test cases = N + 1 (where N = # of conditions)

**Traceability Chain:**

.. code-block:: text

   System Req â†’ HLR â†’ LLR â†’ Code â†’ Unit Test â†’ Integration Test

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ **10. EXAM QUESTIONS**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**Q1:** What is the difference between verification and validation?

**A1:**  
- **Verification:** "Are we building the product **right**?" (implementation correctness)
- **Validation:** "Are we building the **right** product?" (requirements correctness)

Example: Verification checks if code matches LLR. Validation checks if HLR meets stakeholder needs.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

**Q2:** For DAL A software, you have a condition `(A && B && C)`. How many minimum test cases are needed for MC/DC?

**A2:** **4 test cases** (N+1 rule, where N=3 conditions).  
Each test must independently toggle one condition while holding others constant to prove that condition affects the decision outcome.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

**Q3:** Your code has 100% statement coverage but a bug still escapes. Why?

**A3:** Statement coverage does NOT guarantee:
- Both TRUE and FALSE branches tested (need decision coverage)
- Independent condition testing (need MC/DC for DAL A/B)
- Requirements coverage (need requirements-based tests)

Example: `if (A && B)` might only be tested with A=T, B=T, missing the case where A=F.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

**Q4:** What is bi-directional traceability and why is it required?

**A4:**  
- **Forward:** HLR â†’ LLR â†’ Code â†’ Tests (proves all requirements implemented)
- **Backward:** Tests â†’ Code â†’ LLR â†’ HLR (proves no orphan code)

Required by DO-178C Â§6.3 to demonstrate complete coverage and prevent undocumented features.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

**Q5:** When is tool qualification (TQL-1) required for a coverage analyzer?

**A5:** When the tool's output is used as **DO-178C certification evidence** without independent verification. If the DER (Designated Engineering Representative) relies on VectorCAST's MC/DC report, the tool must have a Tool Qualification Data Package proving its correctness.

Alternative: Manually verify a sample of coverage results (but impractical for large projects).

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“š **11. FURTHER READING**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**Standards:**

ğŸ“œ **RTCA DO-178C / EUROCAE ED-12C**  
   Software Considerations in Airborne Systems (2011)  
   https://www.rtca.org/content/standards-documents

ğŸ“œ **ISO 26262-6** (Automotive equivalent)  
   Product development at the software level

ğŸ“œ **IEC 61508-3** (Industrial functional safety)  
   Software requirements for safety-related systems

**Books:**

ğŸ“– *"DO-178C / ED-12C Explained"* â€” Leanna Rierson  
ğŸ“– *"Software Testing and Continuous Quality Improvement"* â€” Burnstein  
ğŸ“– *"Practical Software Testing"* â€” Ilene Burnstein

**Papers:**

ğŸ“„ "MC/DC vs. Decision Coverage: Empirical Study" (IEEE Aerospace 2015)  
ğŸ“„ "Traceability in Safety-Critical Systems" (SafeComp 2018)

**Training:**

ğŸ“ **AFuzion DO-178C Training** (5-day course, includes V&V module)  
ğŸ“ **Rapita Systems Coverage Analysis Workshop**  
ğŸ“ **Vector Software VectorCAST Certification**

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… **COMPLETION CHECKLIST**
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

- [ ] Understand verification vs. validation (two-question test)
- [ ] Memorize coverage requirements for DAL A/B/C
- [ ] Calculate MC/DC test cases (N+1 formula)
- [ ] Explain bi-directional traceability
- [ ] List 4 verification methods (T, I, A, D)
- [ ] Describe integration testing strategies
- [ ] Identify tool qualification criteria (TQL-1)
- [ ] Recognize common V&V pitfalls (5 listed)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ **MEMORABLE ANALOGIES**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**Verification = Building Inspector**  
- Checks if house matches blueprints (code matches design)

**Validation = Homeowner Walkthrough**  
- Checks if house meets family needs (requirements meet stakeholder intent)

**MC/DC = Circuit Breaker Testing**  
- Must prove each breaker independently trips the system

**Traceability = Supply Chain Tracking**  
- Follow coffee bean from farm â†’ roaster â†’ cafe â†’ cup

**100% Coverage = No Dark Corners**  
- Every room in the house has been walked through (but doesn't guarantee furniture is correct!)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸŒŸ **KEY TAKEAWAYS**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1ï¸âƒ£ **V&V â‰  Just Testing:**  
   Verification includes reviews, analysis, inspections (not just test execution)

2ï¸âƒ£ **Requirements-Based Testing Comes First:**  
   Coverage is a verification activity, not a test design method

3ï¸âƒ£ **MC/DC is Expensive but Necessary:**  
   For DAL A/B, MC/DC catches bugs that decision coverage misses

4ï¸âƒ£ **Traceability is Your Legal Defense:**  
   In an accident investigation, traceability proves due diligence

5ï¸âƒ£ **Tool Qualification is NOT Optional:**  
   If FAA relies on your tool, the tool needs its own certification

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**Document Status:** âœ… **COMPREHENSIVE V&V GUIDE COMPLETE**  
**Created:** January 14, 2026  
**Next Steps:** Apply to actual project, customize for specific DAL level

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
