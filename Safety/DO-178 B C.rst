
.. contents:: ğŸ“‘ Quick Navigation
   :depth: 2
   :local:


**ğŸŸ¢ ğŸŸ¢ DO-178B / ğŸŸ¢ ğŸŸ¢ DO-178C Cheat Sheet**  
â­ (Comparison & Key Concepts â€“ valid for avionics software certification in 2025â€“2026)

ğŸŸ¢ ğŸŸ¢ DO-178B (1992) is now **obsolete** for new projects, but still appears in legacy systems.  
ğŸŸ¢ ğŸŸ¢ DO-178C (2011 + supplements) is the **current standard** required by FAA/EASA for new airborne software.

ğŸ“Œ 1. Quick Comparison Table â€“ ğŸŸ¢ ğŸŸ¢ DO-178B vs ğŸŸ¢ ğŸŸ¢ DO-178C

Aspect                        | ğŸŸ¢ ğŸŸ¢ DO-178B (1992)                          | ğŸŸ¢ ğŸŸ¢ DO-178C (2011 + supplements)                     | Practical Impact (2025â€“2026)
------------------------------|------------------------------------------|--------------------------------------------------|-------------------------------------
**Objective tables**          | 6 tables (Aâ€“F)                           | Consolidated into Table A-1 to A-9               | Easier to navigate
**Tool qualification**        | Very strict â€“ almost all tools qualified | TCL (Tool Confidence Level) 1â€“3                  | Much less painful
**Model-based development**   | Not supported                            | Explicitly supported (ğŸŸ¢ ğŸŸ¢ DO-331 supplement)         | MBDA / Simulink widely used
**Formal methods**            | Barely mentioned                         | Explicit supplement (ğŸŸ¢ ğŸŸ¢ DO-333)                     | Used for high-criticality code
**Object code verification**  | Required for Level A                     | More flexible with supplements                   | Less rework if using qualified compilers
**Traceability**              | Required                                 | Stronger emphasis + automation encouraged        | Tools like Polarion / DOORS mandatory
**Supplements**               | None                                     | 4 official: ğŸŸ¢ ğŸŸ¢ DO-330,331,332,333                   | Critical for modern workflows
**Legacy acceptance**         | Still accepted for changes to old systems| Not accepted for new certification               | Reverse engineering common

ğŸ“¡ 2. Software Levels (Development Assurance Level â€“ DAL)

Level | Failure Condition Category          | Typical Function Examples                     | Objectives to satisfy
------|--------------------------------------|-----------------------------------------------|-----------------------
**A** | Catastrophic (aircraft loss / fatalities) | Primary flight controls, engine FADEC, autopilot servos | Highest â€“ ~71 objectives
**B** | Hazardous / Severe-Major             | Flight management, display systems, TCAS      | High â€“ ~69 objectives
**C** | Major                                | Weather radar, cabin pressurization           | Medium â€“ ~50 objectives
â­ **D** | Minor                                | Non-critical displays, maintenance functions  | Low â€“ ~30 objectives
**E** | No safety effect                     | Passenger entertainment, cabin lights         | Minimal â€“ traceability only

**Most avionics projects are Level A or B.**

ğŸ“Œ 3. Key Process Documents (ğŸŸ¢ ğŸŸ¢ DO-178C)

Document / Activity              | Purpose / When Produced                     | Typical Review / Audit Focus
---------------------------------|---------------------------------------------|--------------------------------
**Plan for Software Aspects of Certification (PSAC)** | Top-level planning document                 | FAA/EASA review early
**Software Development Plan**    | How you will develop (tools, methods, standards) | Consistency with PSAC
**Software Verification Plan**   | How you will verify (reviews, tests, analysis) | Coverage metrics
**Software Configuration Management Plan** | Version control, baselines, problem reporting | Traceability & reproducibility
**Software Quality Assurance Plan** | Independence, audits, non-conformance       | SQA independence
**Software Requirements Standards** | Criteria for writing low-level requirements | Consistency, verifiability
**Software Design Standards**    | How architecture & low-level design is done | Modularity, safety patterns
**Software Code Standards**      | Coding rules (MISRA C subset, CERT-C, etc.) | Static analysis compliance

ğŸŸ¢ ğŸŸ¢ âœ… 4. Verification & Testing Objectives (Table A-6 / A-7 simplified)

Activity                              | Level A | Level B | Level C | Level D | Notes
--------------------------------------|---------|---------|---------|---------|-------
**Requirements-based testing**        | 100%    | 100%    | 100%    | â€”       | Normal & robustness cases
**MC/DC coverage**                    | 100%    | â€”       | â€”       | â€”       | Modified Condition/Decision Coverage (Level A only)
**Statement coverage**                | â€”       | 100%    | 100%    | â€”       | 
**Decision coverage**                 | â€”       | 100%    | â€”       | â€”       | 
**Data coupling & control coupling**  | 100%    | 100%    | â€”       | â€”       | 
**Object code to source traceability**| 100%    | â€”       | â€”       | â€”       | Especially if compiler not qualified
**Low-level requirements coverage**   | 100%    | 100%    | â€”       | â€”       | 

ğŸ“š 5. Supplements â€“ Quick Reference (ğŸŸ¢ ğŸŸ¢ DO-178C ecosystem)

Supplement | Title / Focus                               | When you must reference it
-----------|---------------------------------------------|---------------------------
**ğŸŸ¢ ğŸŸ¢ DO-330** | Software Tool Qualification Considerations  | Every tool used in development/verification
**ğŸŸ¢ ğŸŸ¢ DO-331** | Model-Based Development & Verification      | Simulink/Stateflow, SCADE, SysML
**ğŸŸ¢ ğŸŸ¢ DO-332** | Object-Oriented Technology & Related Techniques | C++, Java (rare in avionics)
**ğŸŸ¢ ğŸŸ¢ DO-333** | Formal Methods Supplement                   | Model checking, theorem proving (e.g. AstrÃ©e, Frama-C, Coq)

âš™ï¸ 6. Tool Qualification Levels (ğŸŸ¢ ğŸŸ¢ DO-330 â€“ much easier than ğŸŸ¢ ğŸŸ¢ DO-178B)

TCL | Criteria                                    | Typical Tools
----|---------------------------------------------|---------------
**TCL-1** | Output directly used as safety artifact     | Code generator that produces Level A code
**TCL-2** | Output affects development/verification     | Static analyzer, test generator, compiler
**TCL-3** | Support tool â€“ no direct impact             | Most configuration management, requirements tools

**TCL-3 is the most common qualification level in 2025â€“2026.**

âš™ï¸ 7. Quick One-liners (what certification auditors & engineers say)

- â€œLevel A code still needs MC/DC â€” no way around it.â€
- â€œIf you use Simulink, you must follow ğŸŸ¢ ğŸŸ¢ DO-331.â€
- â€œCompiler is TCL-2 unless you prove it otherwise.â€
- â€œWe use AstrÃ©e for stack & WCET analysis â€” helps Level A.â€
- â€œTraceability from high-level requirements to object code is non-negotiable.â€
â­ - â€œChange impact analysis is critical for incremental certification.â€
- â€œSQA must be independent â€” no exceptions.â€

ğŸ“Œ 8. Modern Reality (2025â€“2026)

- **Most new avionics** â†’ ğŸŸ¢ ğŸŸ¢ DO-178C + ğŸŸ¢ ğŸŸ¢ DO-331 (model-based)
- **Formal methods (ğŸŸ¢ ğŸŸ¢ DO-333)** â†’ growing for Level A critical code
- **Agile + ğŸŸ¢ ğŸŸ¢ DO-178C** â†’ possible with strong planning & tool support
- **Toolchain** â†’ VectorCAST, LDRA, Cantata, QAC, Polyspace, SCADE, Simulink Design Verifier, AstrÃ©e
- **Certification time** â†’ 18â€“36 months typical for Level A/B

ğŸŸ¢ ğŸŸ¢ Good luck with your avionics certification effort!  
The biggest time sinks are usually **MC/DC coverage**, **tool qualification**, **traceability gaps**, and **change impact analysis** â€” start early with PSAC and tool selection.

================================================================================

**Last updated:** January 2026

================================================================================

**Last updated:** January 2026

================================================================================

**Last updated:** January 2026
